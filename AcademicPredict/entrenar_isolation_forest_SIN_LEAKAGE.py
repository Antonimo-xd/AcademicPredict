"""
===============================================================================
ISOLATION FOREST - ENTRENAMIENTO SIN DATA LEAKAGE
===============================================================================

CONCEPTO EDUCATIVO: ¬øQu√© es Isolation Forest?
----------------------------------------------
Isolation Forest es un algoritmo de DETECCI√ìN DE ANOMAL√çAS, no de predicci√≥n
directa. No predice "abandonar√° o no", sino que identifica estudiantes con
comportamiento AT√çPICO.

INTUICI√ìN:
Imagina un bosque de √°rboles de decisi√≥n. Los estudiantes "normales" est√°n
todos juntos (necesitas muchas preguntas para aislarlos). Los estudiantes
"raros" est√°n solos (pocas preguntas los a√≠slan).

EJEMPLO PR√ÅCTICO:
- Estudiante normal: Notas medias + asistencia media + comportamiento t√≠pico
  ‚Üí Necesitas ~10 preguntas para aislarlo del grupo
  
- Estudiante an√≥malo: Notas altas + CERO asistencia LMS + comportamiento extra√±o
  ‚Üí Necesitas solo 2-3 preguntas para aislarlo
  ‚Üí ¬°ALERTA! Posible caso de riesgo

APLICACI√ìN EN NUESTRO PROYECTO:
-------------------------------
Usamos Isolation Forest como PRIMERA L√çNEA de detecci√≥n:
1. Identifica estudiantes con patrones at√≠picos
2. Genera "anomaly scores" (puntajes de anomal√≠a)
3. Estos scores se pueden usar solos O combinarse con otros modelos

DIFERENCIA CLAVE vs VERSI√ìN CON LEAKAGE:
---------------------------------------
‚ùå ANTES: 66 features (inclu√≠a informaci√≥n del futuro)
‚úÖ AHORA: 43 features (solo informaci√≥n disponible PRE-deserci√≥n)

Autor: Basti√°n
Fecha: Noviembre 2024
Proyecto: AcademicPredict
===============================================================================
"""

import pickle
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import IsolationForest
from sklearn.metrics import classification_report, confusion_matrix
import joblib
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# ============================================================================
# CONFIGURACI√ìN
# ============================================================================

# Paths de archivos
TRAIN_TEST_PATH = 'modelos_ml/train_test_splits_SIN_LEAKAGE.pkl'
MODEL_OUTPUT_PATH = 'modelos_ml/isolation_forest_model_SIN_LEAKAGE.pkl'
RESULTS_DIR = 'resultados_ml/'

# Configuraci√≥n del modelo
"""
EXPLICACI√ìN DE HIPERPAR√ÅMETROS:
-------------------------------
- contamination: % esperado de anomal√≠as (estudiantes en riesgo)
  En nuestro caso: 0.058 (5.8%) porque esa es la tasa hist√≥rica de deserci√≥n
  
- n_estimators: N√∫mero de √°rboles en el "bosque"
  M√°s √°rboles = m√°s preciso pero m√°s lento
  100 es un buen balance
  
- max_samples: Cu√°ntas muestras usa cada √°rbol
  'auto' = usa 256 muestras autom√°ticamente (eficiente)
  
- random_state: Semilla para reproducibilidad
  42 es una convenci√≥n (referencia a "Gu√≠a del Autoestopista Gal√°ctico")
"""
ISO_FOREST_CONFIG = {
    'contamination': 0.058,  # 5.8% tasa de deserci√≥n
    'n_estimators': 100,
    'max_samples': 'auto',
    'random_state': 42,
    'n_jobs': -1  # Usa todos los cores del CPU
}

print("=" * 80)
print("üå≤ ENTRENAMIENTO: ISOLATION FOREST SIN DATA LEAKAGE")
print("=" * 80)
print(f"\nüìÖ Fecha y hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print(f"\nüìÅ Cargando datos desde: {TRAIN_TEST_PATH}")

# ============================================================================
# 1. CARGAR DATOS LIMPIOS (SIN LEAKAGE)
# ============================================================================

"""
CONCEPTO EDUCATIVO: ¬øPor qu√© cargar pickle?
-------------------------------------------
Los datos ya fueron:
1. Limpiados (sin leakage)
2. Normalizados con StandardScaler
3. Divididos en train/test con stratify
4. Balanceados con SMOTE (solo train)

Cargar el pickle nos ahorra repetir todo ese proceso.
"""

try:
    with open(TRAIN_TEST_PATH, 'rb') as f:
        data = pickle.load(f)
    
    X_train = data['X_train_balanced']  # Ya balanceado con SMOTE
    X_test = data['X_test']
    y_train = data['y_train_balanced']
    y_test = data['y_test']
    feature_names = data['feature_names']
    
    print(f"\n‚úÖ Datos cargados exitosamente")
    print(f"\nüìä ESTAD√çSTICAS DEL DATASET SIN LEAKAGE:")
    print(f"   - Features totales: {len(feature_names)}")
    print(f"   - Registros train: {X_train.shape[0]:,}")
    print(f"   - Registros test: {X_test.shape[0]:,}")
    print(f"   - Balance en train: {np.sum(y_train == 1):,} abandonos / {np.sum(y_train == 0):,} no abandonos")
    print(f"   - Balance en test: {np.sum(y_test == 1):,} abandonos / {np.sum(y_test == 0):,} no abandonos")
    
except FileNotFoundError:
    print(f"\n‚ùå ERROR: No se encontr√≥ el archivo {TRAIN_TEST_PATH}")
    print("\nüí° SOLUCI√ìN: Primero debes ejecutar preparar_datos_ml_SIN_LEAKAGE.py")
    exit(1)

# ============================================================================
# 2. ENTRENAR ISOLATION FOREST
# ============================================================================

print("\n" + "=" * 80)
print("üéØ PASO 2: ENTRENAMIENTO DEL MODELO")
print("=" * 80)

print(f"\nüîß Configuraci√≥n del modelo:")
for key, value in ISO_FOREST_CONFIG.items():
    print(f"   - {key}: {value}")

"""
CONCEPTO EDUCATIVO: ¬øC√≥mo entrena Isolation Forest?
---------------------------------------------------
1. Construye 100 √°rboles de decisi√≥n aleatorios
2. Cada √°rbol hace splits aleatorios en las features
3. Cuenta cu√°ntos splits necesita para aislar cada estudiante
4. Estudiantes f√°ciles de aislar = ANOMAL√çAS (posibles desertores)
5. Estudiantes dif√≠ciles de aislar = NORMALES

MATEM√ÅTICA SIMPLIFICADA:
- Anomaly Score = 2^(-profundidad_promedio / c)
- Donde c = constante de normalizaci√≥n
- Score cercano a 1 = Anomal√≠a
- Score cercano a 0 = Normal
"""

iso_forest = IsolationForest(**ISO_FOREST_CONFIG)

print("\n‚è≥ Entrenando modelo (esto puede tomar unos minutos)...")
iso_forest.fit(X_train)

print("‚úÖ Modelo entrenado exitosamente")

# ============================================================================
# 3. GENERAR PREDICCIONES Y ANOMALY SCORES
# ============================================================================

print("\n" + "=" * 80)
print("üéØ PASO 3: GENERACI√ìN DE PREDICCIONES")
print("=" * 80)

"""
CONCEPTO EDUCATIVO: Diferencia entre predict() y score_samples()
----------------------------------------------------------------
- predict(): Devuelve 1 (normal) o -1 (anomal√≠a) ‚Üí Clasificaci√≥n binaria
- score_samples(): Devuelve score continuo ‚Üí M√°s informaci√≥n

Nosotros usaremos ambos:
- predict() para m√©tricas de clasificaci√≥n
- score_samples() para ranking de riesgo
"""

# Predicciones en conjunto de test
y_pred = iso_forest.predict(X_test)
anomaly_scores = iso_forest.score_samples(X_test)

# Convertir predicciones: -1 (anomal√≠a) ‚Üí 1 (abandono), 1 (normal) ‚Üí 0 (no abandono)
y_pred_binary = np.where(y_pred == -1, 1, 0)

print("\nüìä DISTRIBUCI√ìN DE PREDICCIONES:")
print(f"   - Predichos como NORMALES: {np.sum(y_pred_binary == 0):,} ({np.sum(y_pred_binary == 0)/len(y_pred_binary)*100:.2f}%)")
print(f"   - Predichos como ANOMAL√çAS: {np.sum(y_pred_binary == 1):,} ({np.sum(y_pred_binary == 1)/len(y_pred_binary)*100:.2f}%)")

# ============================================================================
# 4. EVALUACI√ìN DEL MODELO
# ============================================================================

print("\n" + "=" * 80)
print("üìà PASO 4: EVALUACI√ìN DEL MODELO")
print("=" * 80)

"""
CONCEPTO EDUCATIVO: M√©tricas para detecci√≥n de anomal√≠as
--------------------------------------------------------
Como Isolation Forest no fue entrenado supervisadamente,
sus m√©tricas ser√°n DIFERENTES a XGBoost:

- Precision: De los que marcamos como anomal√≠as, ¬øcu√°ntos realmente lo son?
- Recall: De todos los que realmente son anomal√≠as, ¬øcu√°ntos detectamos?
- F1-Score: Balance entre precision y recall

INTERPRETACI√ìN ESPERADA:
- Precision ~60-70%: 6-7 de cada 10 alertas son correctas
- Recall ~50-60%: Detectamos 5-6 de cada 10 desertores reales
- Esto es NORMAL para detecci√≥n no supervisada
"""

# Reporte de clasificaci√≥n
print("\nüìä REPORTE DE CLASIFICACI√ìN:")
print("\n" + classification_report(y_test, y_pred_binary, 
                                   target_names=['No Abandono', 'Abandono'],
                                   digits=4))

# Matriz de confusi√≥n
cm = confusion_matrix(y_test, y_pred_binary)

print("üìä MATRIZ DE CONFUSI√ìN:")
print("\n                Predicho")
print("                No Abandono  |  Abandono")
print("         " + "-" * 40)
print(f"Real No  |     {cm[0][0]:>6,}     |  {cm[0][1]:>6,}")
print(f"Real S√≠  |     {cm[1][0]:>6,}     |  {cm[1][1]:>6,}")

# Calcular m√©tricas individuales
tn, fp, fn, tp = cm.ravel()
precision = tp / (tp + fp) if (tp + fp) > 0 else 0
recall = tp / (tp + fn) if (tp + fn) > 0 else 0
f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

print(f"\nüéØ M√âTRICAS CLAVE:")
print(f"   - Precision: {precision:.4f} ({precision*100:.2f}%)")
print(f"   - Recall: {recall:.4f} ({recall*100:.2f}%)")
print(f"   - F1-Score: {f1:.4f}")

# ============================================================================
# 5. VISUALIZACIONES
# ============================================================================

print("\n" + "=" * 80)
print("üìä PASO 5: GENERACI√ìN DE VISUALIZACIONES")
print("=" * 80)

# Configurar estilo
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# -------------------------
# 5.1. Matriz de Confusi√≥n
# -------------------------
fig, ax = plt.subplots(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['No Abandono', 'Abandono'],
            yticklabels=['No Abandono', 'Abandono'],
            cbar_kws={'label': 'N√∫mero de estudiantes'},
            ax=ax)
ax.set_xlabel('Predicci√≥n', fontsize=12, fontweight='bold')
ax.set_ylabel('Valor Real', fontsize=12, fontweight='bold')
ax.set_title('Isolation Forest - Matriz de Confusi√≥n\n(SIN Data Leakage)', 
             fontsize=14, fontweight='bold', pad=20)

# Agregar m√©tricas en el t√≠tulo
plt.text(0.5, -0.15, f'Precision: {precision:.2%} | Recall: {recall:.2%} | F1: {f1:.4f}',
         ha='center', transform=ax.transAxes, fontsize=10)

plt.tight_layout()
confusion_path = f'{RESULTS_DIR}isolation_forest_confusion_matrix_SIN_LEAKAGE.png'
plt.savefig(confusion_path, dpi=300, bbox_inches='tight')
print(f"‚úÖ Guardada: {confusion_path}")
plt.close()

# ----------------------------------
# 5.2. Distribuci√≥n de Anomaly Scores
# ----------------------------------
"""
CONCEPTO EDUCATIVO: Interpretaci√≥n de Anomaly Scores
----------------------------------------------------
- Scores NEGATIVOS (m√°s negativos = m√°s an√≥malos)
- Score ~ -0.5 a 0: Estudiantes muy an√≥malos (alto riesgo)
- Score ~ 0 a 0.2: Estudiantes normales (bajo riesgo)

Esto nos permite:
1. Clasificar binariamente (anomal√≠a s√≠/no)
2. RANKING de riesgo (qui√©n es M√ÅS an√≥malo)
"""

fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# Distribuci√≥n general
axes[0].hist(anomaly_scores, bins=50, edgecolor='black', alpha=0.7, color='steelblue')
axes[0].axvline(anomaly_scores.mean(), color='red', linestyle='--', 
                linewidth=2, label=f'Media: {anomaly_scores.mean():.4f}')
axes[0].set_xlabel('Anomaly Score', fontsize=12, fontweight='bold')
axes[0].set_ylabel('Frecuencia', fontsize=12, fontweight='bold')
axes[0].set_title('Distribuci√≥n de Anomaly Scores', fontsize=14, fontweight='bold')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# Distribuci√≥n por clase real
abandono_scores = anomaly_scores[y_test == 1]
no_abandono_scores = anomaly_scores[y_test == 0]

axes[1].hist(no_abandono_scores, bins=30, alpha=0.6, label='No Abandono', 
             color='green', edgecolor='black')
axes[1].hist(abandono_scores, bins=30, alpha=0.6, label='Abandono Real', 
             color='red', edgecolor='black')
axes[1].axvline(abandono_scores.mean(), color='darkred', linestyle='--', 
                linewidth=2, label=f'Media Abandonos: {abandono_scores.mean():.4f}')
axes[1].axvline(no_abandono_scores.mean(), color='darkgreen', linestyle='--', 
                linewidth=2, label=f'Media No Abandonos: {no_abandono_scores.mean():.4f}')
axes[1].set_xlabel('Anomaly Score', fontsize=12, fontweight='bold')
axes[1].set_ylabel('Frecuencia', fontsize=12, fontweight='bold')
axes[1].set_title('Anomaly Scores por Clase Real', fontsize=14, fontweight='bold')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.suptitle('Isolation Forest - An√°lisis de Anomaly Scores (SIN Data Leakage)',
             fontsize=16, fontweight='bold', y=1.02)
plt.tight_layout()
scores_path = f'{RESULTS_DIR}isolation_forest_scores_SIN_LEAKAGE.png'
plt.savefig(scores_path, dpi=300, bbox_inches='tight')
print(f"‚úÖ Guardada: {scores_path}")
plt.close()

# ============================================================================
# 6. GUARDAR MODELO
# ============================================================================

print("\n" + "=" * 80)
print("üíæ PASO 6: GUARDAR MODELO")
print("=" * 80)

# Guardar modelo entrenado
joblib.dump(iso_forest, MODEL_OUTPUT_PATH)
print(f"‚úÖ Modelo guardado: {MODEL_OUTPUT_PATH}")

# Guardar tambi√©n los scores para an√°lisis posterior
scores_data = {
    'anomaly_scores': anomaly_scores,
    'y_test': y_test,
    'y_pred': y_pred_binary,
    'feature_names': feature_names,
    'metrics': {
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'confusion_matrix': cm
    }
}

scores_output_path = MODEL_OUTPUT_PATH.replace('.pkl', '_scores.pkl')
with open(scores_output_path, 'wb') as f:
    pickle.dump(scores_data, f)
print(f"‚úÖ Scores guardados: {scores_output_path}")

# ============================================================================
# 7. RESUMEN FINAL
# ============================================================================

print("\n" + "=" * 80)
print("‚úÖ ENTRENAMIENTO COMPLETADO - ISOLATION FOREST SIN DATA LEAKAGE")
print("=" * 80)

print(f"\nüìä RESUMEN DE M√âTRICAS:")
print(f"   - Precision: {precision:.4f} ({precision*100:.2f}%)")
print(f"   - Recall: {recall:.4f} ({recall*100:.2f}%)")
print(f"   - F1-Score: {f1:.4f}")
print(f"   - Anomal√≠as detectadas: {np.sum(y_pred_binary == 1):,} / {len(y_pred_binary):,}")

print(f"\nüíæ ARCHIVOS GENERADOS:")
print(f"   ‚úÖ {MODEL_OUTPUT_PATH}")
print(f"   ‚úÖ {scores_output_path}")
print(f"   ‚úÖ {confusion_path}")
print(f"   ‚úÖ {scores_path}")

print(f"\nüí° INTERPRETACI√ìN:")
print(f"   Este modelo act√∫a como PRIMERA L√çNEA de detecci√≥n.")
print(f"   Identifica estudiantes con patrones at√≠picos que podr√≠an estar en riesgo.")
print(f"   Los anomaly scores pueden usarse para:")
print(f"   - Ranking de prioridad de intervenci√≥n")
print(f"   - Combinaci√≥n con otros modelos (ensemble)")
print(f"   - Alertas tempranas autom√°ticas")

print("\n" + "=" * 80)
print("üéâ ¬°PROCESO FINALIZADO!")
print("=" * 80)